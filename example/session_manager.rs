use dashmap::DashMap;
use log::{debug, error, info};
use std::{collections::VecDeque, fmt::Debug, future::Future, hash::Hash, time::Duration};
use tokio::{
	select,
	sync::{mpsc, oneshot},
	time::sleep,
};

pub trait Worker
where
	Self: Sized + Send,
{
	type Context: 'static + Send + Sized;
	type Request: 'static + Send + Sized;
	type Response: 'static + Send + Sized;
	type Id: 'static + Hash + PartialOrd + Eq + Clone + Send + Debug;

	fn create(id: &Self::Id, context: Self::Context) -> impl Future<Output = Self> + Send;

	fn handle(&mut self, request: Self::Request) -> impl Future<Output = Self::Response> + Send;

	fn destroy(self) -> impl Future<Output = Self::Response> + Send;
}

#[must_use = "The potential non-sent cases should be handled"]
pub enum EnqueueResult {
	WorkerAtCapacity,
	NoWorker,
	Sent,
}

#[must_use = "The potential non-response cases should be handled"]
pub enum PollWhileResult<T> {
	NoWorker,
	WorkerAtCapacity,
	Timeout,
	Ceeded,
	Response(T),
}

#[must_use = "The potential non-response cases should be handled"]
pub enum PollResult<T> {
	NoWorker,
	WorkerAtCapacity,
	Ceeded,
	Response(T),
}

#[must_use = "The potential non-response cases should be handled"]
pub enum WaiterNextResult<T> {
	/// A waiter was attached, but after being attached, the worker was terminated. This could be an automatic termination due to inactivity (see `QueueBuilder::terminate_worker_after`)
	/// or a direct call to `Queue::terminate`
	WorkerTerminated,
	/// A response was generated by the worker
	Response(T),
}

#[must_use = "The potential non-attached cases should be handled"]
pub enum AttachWaiterResult<Response> {
	/// There is no worker with the given id that a waiter can be attached to.
	NoWorker,
	/// The worker is currently at capacity. Either increase the queue's max length or try again later
	WorkerAtCapacity,
	/// A waiter was attached
	Waiter(QueueWaiter<Response>),
}

enum InternalPollResponse<T: Sized> {
	Ok(T),
	Ceeded,
}

enum TaskMessage<Request: Sized, Response: Sized> {
	Poll {
		responder: oneshot::Sender<InternalPollResponse<Response>>,
	},
	RegisterSender {
		sender: mpsc::Sender<Response>,
	},
	Enqueue {
		request: Request,
	},
}

struct SpawnMessage<W: Worker> {
	id: W::Id,
	context: W::Context,
	message_receiver: mpsc::Receiver<TaskMessage<W::Request, W::Response>>,
}

struct QueueOptions {
	max_length: usize,
	terminate_worker_after: Duration,
}

impl Default for QueueOptions {
	fn default() -> Self {
		QueueOptions {
			max_length: 5,
			terminate_worker_after: Duration::from_secs(60 * 20),
		}
	}
}

#[derive(Default)]
pub struct QueueBuilder {
	options: QueueOptions,
}

impl QueueBuilder {
	/// The maxium length of the queue for a given worker. If `length` tasks are enqueued before the worker has an opportunity to get to them,
	/// the `length + 1` enqueue call will yield `EnqueueResult::WorkerAtCapacity`
	///
	/// It is not just `Queue::enqueue` that is held to this standard. `Queue::attach_waiter`, `Queue::poll`, and `Queue::poll_until` will not
	/// perform their respective operations if the queue is full. Additionally, if a single `Worker::handle` call is taking a long time, the
	/// aforementinoed operations contribute to the queue reaching it's max length.
	pub fn max_length(mut self, length: usize) -> QueueBuilder {
		self.options.max_length = length;

		self
	}

	/// The amount of inactivity after which a worker is automatically terminated. Defaults to 20 minutes.
	///
	/// NOTE: polling is considered to be activity
	pub fn terminate_worker_after(mut self, duration: Duration) -> QueueBuilder {
		self.options.terminate_worker_after = duration;

		self
	}

	pub fn build<W: Worker + Send + 'static>(self) -> Queue<W> {
		Queue::new(self.options)
	}
}

pub struct Queue<W: Worker> {
	max_length: usize,
	spawn_sender: mpsc::Sender<SpawnMessage<W>>,
	map: DashMap<W::Id, mpsc::Sender<TaskMessage<W::Request, W::Response>>>,
}

impl<W: Worker + Send + 'static> Queue<W> {
	fn new(options: QueueOptions) -> Queue<W> {
		let (spawn_sender, spawn_receiver) = mpsc::channel(1000);

		tokio::spawn(async move { drive_workers(options.terminate_worker_after, spawn_receiver).await });

		Queue {
			max_length: options.max_length,
			spawn_sender,
			map: DashMap::new(),
		}
	}

	/// Spawn a new worker. Tasks can be enqueued by calling `Queue::enqueue` and passing along an `id`. Calls `Worker::create` with `context`.
	pub async fn spawn(&self, id: W::Id, context: W::Context) {
		let (sender, receiver) = mpsc::channel(1000);
		let id_to_insert = id.clone();

		// We want to do as little as possible in here because it will keep a mutex locked
		{
			self.map.insert(id_to_insert, sender);
		}

		let send_res = self
			.spawn_sender
			.send(SpawnMessage {
				id,
				context,
				message_receiver: receiver,
			})
			.await;

		if let Err(_) = send_res {
			error!("The spawning task was closed, which should only happen when this object is dropped. It wasn't dropped though, because we are using it");
		}
	}

	/// Attach a waiter to the worker referenced by `id`. Waiters always take precident over polling, so if there is an active waiter, all responses will be immediately
	/// piped to it and poll calls will hang until the the next response after the waiter is dropped.
	pub fn attach_waiter(&self, id: &W::Id) -> AttachWaiterResult<W::Response> {
		let (sender, receiver) = mpsc::channel(1000);
		let message = TaskMessage::RegisterSender { sender };

		let send_res = {
			let task_sender = match self.map.get(id) {
				Some(sender) => sender,
				None => return AttachWaiterResult::NoWorker,
			};

			task_sender.try_send(message)
		};

		match send_res {
			Err(mpsc::error::TrySendError::Full(_)) => return AttachWaiterResult::WorkerAtCapacity,
			Err(mpsc::error::TrySendError::Closed(_)) => {
				self.map.remove(id);

				return AttachWaiterResult::NoWorker;
			}
			_ => (),
		};

		AttachWaiterResult::Waiter(QueueWaiter { receiver })
	}

	/// Enqueue a new request for the worker referenced by `id` to pick up. The response can be retrived by either polling or attaching a waiter.
	///
	/// Once the worker is ready for a new task, `Worker::handle` will be called with this `request`.
	pub fn enqueue(&self, id: &W::Id, request: W::Request) -> EnqueueResult {
		let message = TaskMessage::Enqueue { request };

		let send_res = {
			let task_sender = match self.map.get(id) {
				Some(sender) => sender,
				None => return EnqueueResult::NoWorker,
			};

			task_sender.try_send(message)
		};

		match send_res {
			Err(mpsc::error::TrySendError::Full(_)) => return EnqueueResult::WorkerAtCapacity,
			Err(mpsc::error::TrySendError::Closed(_)) => {
				self.map.remove(id);

				return EnqueueResult::NoWorker;
			}
			_ => (),
		};

		EnqueueResult::Sent
	}

	/// Poll for a waiting worker response. If there is already a waiting poll, the existing poll will immediately return `PollResult::Ceeded` or `PollWhileResult::Ceeded`.
	pub async fn poll(&self, id: &W::Id) -> PollResult<W::Response> {
		let (responder, receiver) = oneshot::channel();
		let message = TaskMessage::Poll { responder };

		let send_res = {
			let task_sender = match self.map.get(id) {
				Some(sender) => sender,
				None => return PollResult::NoWorker,
			};

			task_sender.try_send(message)
		};

		match send_res {
			Err(mpsc::error::TrySendError::Full(_)) => return PollResult::WorkerAtCapacity,
			Err(mpsc::error::TrySendError::Closed(_)) => {
				self.map.remove(id);

				return PollResult::NoWorker;
			}
			_ => (),
		};

		let response = match receiver.await {
			Ok(InternalPollResponse::Ok(response)) => response,
			Ok(InternalPollResponse::Ceeded) => return PollResult::NoWorker,
			Err(_) => return PollResult::NoWorker,
		};

		PollResult::Response(response)
	}

	/// Poll for a waiting worker response, but timeout after `duration`. If there is already a waiting poll, the existing poll will immediately return
	/// `PollResult::Ceeded` or `PollWhileResult::Ceeded`.
	pub async fn poll_while(&self, id: &W::Id, duration: Duration) -> PollWhileResult<W::Response> {
		select! {
			result = self.poll(id) => match result {
				PollResult::NoWorker => PollWhileResult::NoWorker,
				PollResult::WorkerAtCapacity => PollWhileResult::WorkerAtCapacity,
				PollResult::Ceeded => PollWhileResult::Ceeded,
				PollResult::Response(response)=> PollWhileResult::Response(response),
			 },
			_ = sleep(duration) => PollWhileResult::Timeout
		}
	}
}

pub struct QueueWaiter<Response> {
	receiver: mpsc::Receiver<Response>,
}

impl<Response> QueueWaiter<Response> {
	pub async fn next(&mut self) -> WaiterNextResult<Response> {
		match self.receiver.recv().await {
			Some(response) => WaiterNextResult::Response(response),
			None => WaiterNextResult::WorkerTerminated,
		}
	}
}

async fn drive_workers<W: Worker>(worker_inactivity_timeout: Duration, mut spawn_receiver: mpsc::Receiver<SpawnMessage<W>>) {
	loop {
		let SpawnMessage {
			id,
			context,
			mut message_receiver,
		} = match spawn_receiver.recv().await {
			Some(message) => message,
			None => break,
		};

		tokio::spawn(async move {
			let mut worker = W::create(&id, context).await;
			let mut response_list = VecDeque::<W::Response>::new();
			let mut response_sender = Option::<mpsc::Sender<W::Response>>::None;
			let mut single_response_sender = Option::<oneshot::Sender<InternalPollResponse<W::Response>>>::None;

			loop {
				let message = select! {
					message = message_receiver.recv() => match message {
						Some(message) => message,
						None => {
							debug!("task {id:?} was manually terminated");

							break
						},
					},
					_ = sleep(worker_inactivity_timeout) => {
						debug!("task {id:?} was terminated due to an inactivity timeout of {}s", worker_inactivity_timeout.as_secs());

						break
					},
				};

				match message {
					TaskMessage::Poll { responder } => {
						// drop the responder without sending if there is already a listening waiter
						if let None = response_sender {
							match response_list.pop_front() {
								Some(waiting_response) => {
									if let Err(rejected) = responder.send(InternalPollResponse::Ok(waiting_response)) {
										response_list.push_front(match rejected {
											InternalPollResponse::Ok(rejected) => rejected,
											InternalPollResponse::Ceeded => unreachable!(),
										});
									}
								}
								None => {
									if let Some(old_responder) = single_response_sender.replace(responder) {
										let _ = old_responder.send(InternalPollResponse::Ceeded);
									}
								}
							}
						}
					}
					TaskMessage::RegisterSender { sender } => {
						let mut did_close = false;

						loop {
							let waiting_message = match response_list.pop_front() {
								Some(response) => response,
								None => break,
							};

							match sender.send(waiting_message).await {
								Err(mpsc::error::SendError(message)) => {
									response_list.push_front(message);
									did_close = true;
								}
								_ => (),
							}
						}

						if !did_close {
							response_sender = Some(sender);
						}
					}
					TaskMessage::Enqueue { request } => {
						let response = worker.handle(request).await;

						if let Some(sender) = &response_sender {
							if let Err(mpsc::error::SendError(rejected)) = sender.send(response).await {
								response_list.push_back(rejected);
								response_sender = None;
							};
						} else if let Some(sender) = single_response_sender.take() {
							if let Err(rejected) = sender.send(InternalPollResponse::Ok(response)) {
								response_list.push_back(match rejected {
									InternalPollResponse::Ok(rejected) => rejected,
									InternalPollResponse::Ceeded => unreachable!(),
								});
								single_response_sender = None;
							}
						} else {
							response_list.push_back(response);
						}
					}
				}
			}

			info!("running destructor for task {id:?}");
			worker.destroy().await;
		});
	}
}
